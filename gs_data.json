{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "4FA6C0AAAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Yi Ren (任意)", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=4FA6C0AAAAAJ&citpid=8", "affiliation": "Research Scientist, Tiktok", "interests": ["Avatar", "Speech", "Music", "Audio Signal Processing", "Machine Translation"], "email_domain": "@bytedance.com", "homepage": "https://rayeren.github.io/", "citedby": 6017, "publications": {"4FA6C0AAAAAJ:LkGwnXOMwfcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FastSpeech 2: Fast and High-Quality End-to-End Text-to-Speech", "pub_year": "2020"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:LkGwnXOMwfcC", "num_citations": 1387, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13060237915382152145", "cites_id": ["13060237915382152145"]}, "4FA6C0AAAAAJ:qjMakFHDy7sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FastSpeech: Fast, Robust and Controllable Text to Speech", "pub_year": "2019"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:qjMakFHDy7sC", "num_citations": 1150, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6010985130650843722", "cites_id": ["6010985130650843722"]}, "4FA6C0AAAAAJ:qUcmZB5y_30C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Pseudo Numerical Methods for Diffusion Models on Manifolds", "pub_year": "2021"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:qUcmZB5y_30C", "num_citations": 434, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13911281549093893446", "cites_id": ["13911281549093893446"]}, "4FA6C0AAAAAJ:d1gkVwhDpl0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multilingual Neural Machine Translation with Knowledge Distillation", "pub_year": "2019"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:d1gkVwhDpl0C", "num_citations": 264, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5753623392275205285", "cites_id": ["5753623392275205285"]}, "4FA6C0AAAAAJ:qxL8FJ1GzNcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Diffsinger: Diffusion acoustic model for singing voice synthesis", "pub_year": "2021"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:qxL8FJ1GzNcC", "num_citations": 261, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10338801702241816573,17543750673797975335", "cites_id": ["10338801702241816573", "17543750673797975335"]}, "4FA6C0AAAAAJ:NaGl4SEjCO4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Make-an-audio: Text-to-audio generation with prompt-enhanced diffusion models", "pub_year": "2023"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:NaGl4SEjCO4C", "num_citations": 202, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14204166098403262471", "cites_id": ["14204166098403262471"]}, "4FA6C0AAAAAJ:e5wmG9Sq2KIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FastDiff: A Fast Conditional Diffusion Model for High-Quality Speech Synthesis", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:e5wmG9Sq2KIC", "num_citations": 150, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2088823687859195371", "cites_id": ["2088823687859195371"]}, "4FA6C0AAAAAJ:maZDTaKrznsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Prodiff: Progressive fast diffusion model for high-quality text-to-speech", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:maZDTaKrznsC", "num_citations": 143, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9223505264010200019", "cites_id": ["9223505264010200019"]}, "4FA6C0AAAAAJ:35N4QoGY0k4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Audiogpt: Understanding and generating speech, music, sound, and talking head", "pub_year": "2024"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:35N4QoGY0k4C", "num_citations": 127, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10625702268349818855", "cites_id": ["10625702268349818855"]}, "4FA6C0AAAAAJ:9yKSN-GCB0IC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Almost Unsupervised Text to Speech and Automatic Speech Recognition", "pub_year": "2019"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:9yKSN-GCB0IC", "num_citations": 122, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16710802202249302730", "cites_id": ["16710802202249302730"]}, "4FA6C0AAAAAJ:3fE2CSJIrl8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "PopMAG: Pop Music Accompaniment Generation", "pub_year": "2020"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:3fE2CSJIrl8C", "num_citations": 120, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7537456620066024076", "cites_id": ["7537456620066024076"]}, "4FA6C0AAAAAJ:_FxGoFyzp5QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MultiSpeech: Multi-Speaker Text to Speech with Transformer", "pub_year": "2020"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:_FxGoFyzp5QC", "num_citations": 107, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=257446469031533993", "cites_id": ["257446469031533993"]}, "4FA6C0AAAAAJ:KlAtU1dfN6UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "LRSpeech: Extremely low-resource speech synthesis and recognition", "pub_year": "2020"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:KlAtU1dfN6UC", "num_citations": 94, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2976229052422532435", "cites_id": ["2976229052422532435"]}, "4FA6C0AAAAAJ:L8Ckcad2t8MC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multi-Singer: Fast Multi-Singer Singing Voice Vocoder With A Large-Scale Corpus", "pub_year": "2021"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:L8Ckcad2t8MC", "num_citations": 89, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2358855456085494126", "cites_id": ["2358855456085494126"]}, "4FA6C0AAAAAJ:J_g5lzvAfSwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "GeneFace: Generalized and High-Fidelity Audio-Driven 3D Talking Face Synthesis", "pub_year": "2023"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:J_g5lzvAfSwC", "num_citations": 83, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16884839736713936995", "cites_id": ["16884839736713936995"]}, "4FA6C0AAAAAJ:dhFuZR0502QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "PortaSpeech: Portable and High-Quality Generative Text-to-Speech", "pub_year": "2021"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:dhFuZR0502QC", "num_citations": 76, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4177501522773357655", "cites_id": ["4177501522773357655"]}, "4FA6C0AAAAAJ:j3f4tGmQtD8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "GenerSpeech: Towards Style Transfer for Generalizable Out-Of-Domain Text-to-Speech Synthesis", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:j3f4tGmQtD8C", "num_citations": 72, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13191102001080802763", "cites_id": ["13191102001080802763"]}, "4FA6C0AAAAAJ:kNdYIx-mwKoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Deepsinger: Singing voice synthesis with data mined from the web", "pub_year": "2020"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:kNdYIx-mwKoC", "num_citations": 72, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14039303487459192506", "cites_id": ["14039303487459192506"]}, "4FA6C0AAAAAJ:UebtZRa9Y70C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SimulSpeech: End-to-End Simultaneous Speech to Text Translation", "pub_year": "2020"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:UebtZRa9Y70C", "num_citations": 72, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18282202564539184071", "cites_id": ["18282202564539184071"]}, "4FA6C0AAAAAJ:hqOjcs7Dif8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A Study of Non-autoregressive Model for Sequence Generation", "pub_year": "2020"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:hqOjcs7Dif8C", "num_citations": 69, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14794750858649896134", "cites_id": ["14794750858649896134"]}, "4FA6C0AAAAAJ:7PzlFSSx8tAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SingGAN: Generative Adversarial Network For High-Fidelity Singing Voice Generation", "pub_year": "2021"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:7PzlFSSx8tAC", "num_citations": 61, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1698516610881405813", "cites_id": ["1698516610881405813"]}, "4FA6C0AAAAAJ:YOwf2qJgpHMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SongMASS: Automatic Song Writing with Pre-training and Alignment Constraint", "pub_year": "2020"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:YOwf2qJgpHMC", "num_citations": 61, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8751829498121461871", "cites_id": ["8751829498121461871"]}, "4FA6C0AAAAAJ:isC4tDSrTZIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "M4Singer: a Multi-Style, Multi-Singer and Musical Score Provided Mandarin Singing Corpus", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:isC4tDSrTZIC", "num_citations": 58, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1634477637622720706", "cites_id": ["1634477637622720706"]}, "4FA6C0AAAAAJ:hFOr9nPyWt4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Revisiting Over-Smoothness in Text to Speech", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:hFOr9nPyWt4C", "num_citations": 55, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11633660030649739510", "cites_id": ["11633660030649739510"]}, "4FA6C0AAAAAJ:Se3iqnhoufwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "UWSpeech: Speech to Speech Translation for Unwritten Languages", "pub_year": "2020"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:Se3iqnhoufwC", "num_citations": 52, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14535875175215134571", "cites_id": ["14535875175215134571"]}, "4FA6C0AAAAAJ:rO6llkc54NcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Mega-tts: Zero-shot text-to-speech at scale with intrinsic inductive bias", "pub_year": "2023"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:rO6llkc54NcC", "num_citations": 47, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15692405188854768212", "cites_id": ["15692405188854768212"]}, "4FA6C0AAAAAJ:aqlVkmm33-oC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Denoispeech: Denoising text to speech with frame-level noise modeling", "pub_year": "2021"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:aqlVkmm33-oC", "num_citations": 45, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16819689550610351819", "cites_id": ["16819689550610351819"]}, "4FA6C0AAAAAJ:iH-uZ7U-co4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "TranSpeech: Speech-to-Speech Translation With Bilateral Perturbation", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:iH-uZ7U-co4C", "num_citations": 42, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15292967138191810315", "cites_id": ["15292967138191810315"]}, "4FA6C0AAAAAJ:Zph67rFs4hoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Task-Level Curriculum Learning for Non-Autoregressive Neural Machine Translation", "pub_year": "2020"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:Zph67rFs4hoC", "num_citations": 38, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14167179461331368816", "cites_id": ["14167179461331368816"]}, "4FA6C0AAAAAJ:hC7cP41nSMkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "ProsoSpeech: Enhancing Prosody With Quantized Vector Pre-training in Text-to-Speech", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:hC7cP41nSMkC", "num_citations": 37, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=742153645225333053", "cites_id": ["742153645225333053"]}, "4FA6C0AAAAAJ:Wp0gIr-vW9MC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "EMOVIE: A Mandarin Emotion Speech Dataset with a Simple Emotional Text-to-Speech Model", "pub_year": "2021"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:Wp0gIr-vW9MC", "num_citations": 30, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15315350381922618364", "cites_id": ["15315350381922618364"]}, "4FA6C0AAAAAJ:SeFeTyx0c_EC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Make-an-audio 2: Temporal-enhanced text-to-audio generation", "pub_year": "2023"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:SeFeTyx0c_EC", "num_citations": 28, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13517159671265524532", "cites_id": ["13517159671265524532"]}, "4FA6C0AAAAAJ:4DMP91E08xMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "WSRGlow: A Glow-based Waveform Generative Model for Audio Super-Resolution", "pub_year": "2021"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:4DMP91E08xMC", "num_citations": 27, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1218606588393750672", "cites_id": ["1218606588393750672"]}, "4FA6C0AAAAAJ:RHpTSmoSYBkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SyntaSpeech: Syntax-Aware Generative Adversarial Text-to-Speech", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:RHpTSmoSYBkC", "num_citations": 23, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12585565410592421516", "cites_id": ["12585565410592421516"]}, "4FA6C0AAAAAJ:fPk4N6BV_jEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Mega-tts 2: Zero-shot text-to-speech with arbitrary length speech prompts", "pub_year": "2023"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:fPk4N6BV_jEC", "num_citations": 20, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16735322993503076322", "cites_id": ["16735322993503076322"]}, "4FA6C0AAAAAJ:9ZlFYXVOiuMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FedSpeech: Federated Text-to-Speech with Continual Learning", "pub_year": "2021"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:9ZlFYXVOiuMC", "num_citations": 19, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15771162422143074501", "cites_id": ["15771162422143074501"]}, "4FA6C0AAAAAJ:70eg2SAEIzsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Geneface++: Generalized and stable real-time audio-driven 3d talking face generation", "pub_year": "2023"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:70eg2SAEIzsC", "num_citations": 16, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=408392048948677980", "cites_id": ["408392048948677980"]}, "4FA6C0AAAAAJ:abG-DnoFyZgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Sparks of large audio models: A survey and outlook", "pub_year": "2023"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:abG-DnoFyZgC", "num_citations": 15, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16437450415634223230", "cites_id": ["16437450415634223230"]}, "4FA6C0AAAAAJ:ldfaerwXgEUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "CLAPSpeech: Learning Prosody from Text Context with Contrastive Language-Audio Pre-training", "pub_year": "2023"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:ldfaerwXgEUC", "num_citations": 15, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11061604911451895335", "cites_id": ["11061604911451895335"]}, "4FA6C0AAAAAJ:8k81kl-MbHgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FastLR: Non-Autoregressive Lipreading Model with Integrate-and-Fire", "pub_year": "2020"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:8k81kl-MbHgC", "num_citations": 14, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9581806397991323587", "cites_id": ["9581806397991323587"]}, "4FA6C0AAAAAJ:yD5IFk8b50cC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Real3d-portrait: One-shot realistic 3d talking portrait synthesis", "pub_year": "2024"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:yD5IFk8b50cC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4610920972123504276", "cites_id": ["4610920972123504276"]}, "4FA6C0AAAAAJ:blknAaTinKkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Conditional hybrid GAN for melody generation from lyrics", "pub_year": "2023"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:blknAaTinKkC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2906106586410913155", "cites_id": ["2906106586410913155"]}, "4FA6C0AAAAAJ:TQgYirikUcIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Flow-based Unconstrained Lip to Speech Generation", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:TQgYirikUcIC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12941442660143753050", "cites_id": ["12941442660143753050"]}, "4FA6C0AAAAAJ:2P1L_qKh6hAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AMD: Autoregressive Motion Diffusion", "pub_year": "2024"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:2P1L_qKh6hAC", "num_citations": 11, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12776425205176014247", "cites_id": ["12776425205176014247"]}, "4FA6C0AAAAAJ:M05iB0D1s5AC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Av-transpeech: Audio-visual robust speech-to-speech translation", "pub_year": "2023"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:M05iB0D1s5AC", "num_citations": 11, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3031965472100444937", "cites_id": ["3031965472100444937"]}, "4FA6C0AAAAAJ:W7OEmFMy1HYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A study of multilingual neural machine translation", "pub_year": "2019"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:W7OEmFMy1HYC", "num_citations": 11, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18364568791000482325", "cites_id": ["18364568791000482325"]}, "4FA6C0AAAAAJ:BqipwSGYUEgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "VarietySound: Timbre-Controllable Video to Sound Generation via Unsupervised Information Disentanglement", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:BqipwSGYUEgC", "num_citations": 10, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2333085745106701374", "cites_id": ["2333085745106701374"]}, "4FA6C0AAAAAJ:mB3voiENLucC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning the Beauty in Songs: Neural Singing Voice Beautifier", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:mB3voiENLucC", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17442799639671484493", "cites_id": ["17442799639671484493"]}, "4FA6C0AAAAAJ:g5m5HwL7SMYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FluentSpeech: Stutter-Oriented Automatic Speech Editing with Context-Aware Diffusion Models", "pub_year": "2023"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:g5m5HwL7SMYC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7922113499487900716", "cites_id": ["7922113499487900716"]}, "4FA6C0AAAAAJ:JV2RwH3_ST0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Video-Guided Curriculum Learning for Spoken Video Grounding", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:JV2RwH3_ST0C", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9925262944195228948", "cites_id": ["9925262944195228948"]}, "4FA6C0AAAAAJ:k_IJM867U9cC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A Study of Syntactic Multi-Modality in Non-Autoregressive Machine Translation", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:k_IJM867U9cC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4915893506994619638", "cites_id": ["4915893506994619638"]}, "4FA6C0AAAAAJ:HDshCWvjkbEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Parallel and High-Fidelity Text-to-Lip Generation", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:HDshCWvjkbEC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1241053409280770066", "cites_id": ["1241053409280770066"]}, "4FA6C0AAAAAJ:cFHS6HbyZ2cC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Emotion rendering for conversational speech synthesis with heterogeneous graph-based context modeling", "pub_year": "2024"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:cFHS6HbyZ2cC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17146289522653380207", "cites_id": ["17146289522653380207"]}, "4FA6C0AAAAAJ:f2IySw72cVMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Mega-TTS 2: Boosting Prompting Mechanisms for Zero-Shot Speech Synthesis", "pub_year": "2024"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:f2IySw72cVMC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9894513651131202376", "cites_id": ["9894513651131202376"]}, "4FA6C0AAAAAJ:zA6iFVUQeVQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FastDiff 2: Revisiting and incorporating GANs and diffusion models in high-fidelity speech synthesis", "pub_year": "2023"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:zA6iFVUQeVQC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5865263432404926087", "cites_id": ["5865263432404926087"]}, "4FA6C0AAAAAJ:hMod-77fHWUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Sdmuse: Stochastic differential music editing and generation via hybrid representation", "pub_year": "2023"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:hMod-77fHWUC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11006749880187999562", "cites_id": ["11006749880187999562"]}, "4FA6C0AAAAAJ:YFjsv_pBGBYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Diffusion denoising process for perceptron bias in out-of-distribution detection", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:YFjsv_pBGBYC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10567998091823456008", "cites_id": ["10567998091823456008"]}, "4FA6C0AAAAAJ:dfsIfKJdRG4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Unsupervised video domain adaptation for action recognition: A disentanglement perspective", "pub_year": "2023"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:dfsIfKJdRG4C", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7229371039987405583", "cites_id": ["7229371039987405583"]}, "4FA6C0AAAAAJ:ZHo1McVdvXMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Detector guidance for multi-object text-to-image generation", "pub_year": "2023"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:ZHo1McVdvXMC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11690234322079605255", "cites_id": ["11690234322079605255"]}, "4FA6C0AAAAAJ:a0OBvERweLwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Boosting prompting mechanisms for zero-shot speech synthesis", "pub_year": "2023"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:a0OBvERweLwC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2070196773252279258", "cites_id": ["2070196773252279258"]}, "4FA6C0AAAAAJ:4JMBOYKVnBMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "HiFiDenoise: High-Fidelity Denoising Text to Speech with Adversarial Networks", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:4JMBOYKVnBMC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6731775296221460107", "cites_id": ["6731775296221460107"]}, "4FA6C0AAAAAJ:IWHjjKOFINEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MR-SVS: Singing Voice Synthesis with Multi-Reference Encoder", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:IWHjjKOFINEC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18139761552468282156", "cites_id": ["18139761552468282156"]}, "4FA6C0AAAAAJ:HoB7MX3m0LUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Styles2st: Zero-shot style transfer for direct speech-to-speech translation", "pub_year": "2023"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:HoB7MX3m0LUC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5448190074786270793", "cites_id": ["5448190074786270793"]}, "4FA6C0AAAAAJ:RGFaLdJalmkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Dance2MIDI: Dance-driven multi-instrument music generation", "pub_year": "2024"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:RGFaLdJalmkC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16950007266259745371", "cites_id": ["16950007266259745371"]}, "4FA6C0AAAAAJ:u_35RYKgDlwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Prosody-TTS: Improving Prosody with Masked Autoencoder and Conditional Diffusion Model For Expressive Text-to-Speech", "pub_year": "2023"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:u_35RYKgDlwC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6700848495971978849", "cites_id": ["6700848495971978849"]}, "4FA6C0AAAAAJ:3s1wT3WcHBgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Ada-TTA: Towards adaptive high-quality text-to-talking avatar synthesis", "pub_year": "2023"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:3s1wT3WcHBgC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2525485338562235164", "cites_id": ["2525485338562235164"]}, "4FA6C0AAAAAJ:RYcK_YlVTxYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Bag of Tricks for Unsupervised Text-to-Speech", "pub_year": "2023"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:RYcK_YlVTxYC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16760848509932487165", "cites_id": ["16760848509932487165"]}, "4FA6C0AAAAAJ:TFP_iSt0sucC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Dict-TTS: Learning to Pronounce with Prior Dictionary Knowledge for Text-to-Speech", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:TFP_iSt0sucC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18386504940057315518", "cites_id": ["18386504940057315518"]}, "4FA6C0AAAAAJ:D03iK_w7-QYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Benchmarking large multimodal models against common corruptions", "pub_year": "2024"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:D03iK_w7-QYC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5700244330411873493", "cites_id": ["5700244330411873493"]}, "4FA6C0AAAAAJ:4OULZ7Gr8RgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "C2g2: Controllable co-speech gesture generation with latent diffusion model", "pub_year": "2023"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:4OULZ7Gr8RgC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2897936852736297373", "cites_id": ["2897936852736297373"]}, "4FA6C0AAAAAJ:bFI3QPDXJZMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "RefXVC: Cross-Lingual Voice Conversion with Enhanced Reference Leveraging", "pub_year": "2024"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:bFI3QPDXJZMC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1720028842001439522", "cites_id": ["1720028842001439522"]}, "4FA6C0AAAAAJ:_xSYboBqXhAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "EnchantDance: Unveiling the Potential of Music-Driven Dance Movement", "pub_year": "2023"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:_xSYboBqXhAC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6206554651976218334", "cites_id": ["6206554651976218334"]}, "4FA6C0AAAAAJ:mVmsd5A6BfQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "High-Speed and High-Quality Text-to-Lip Generation", "pub_year": "2021"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:mVmsd5A6BfQC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=249661701422637323", "cites_id": ["249661701422637323"]}, "4FA6C0AAAAAJ:GnPB-g6toBAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Prosody-TTS: Self-Supervised Prosody Pretraining with Latent Diffusion For Text-to-Speech"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:GnPB-g6toBAC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3375904935116192063", "cites_id": ["3375904935116192063"]}, "4FA6C0AAAAAJ:b0M2c_1WBrUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MulliVC: Multi-lingual Voice Conversion With Cycle Consistency", "pub_year": "2024"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:b0M2c_1WBrUC", "num_citations": 0}, "4FA6C0AAAAAJ:EUQCXRtRnyEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Generative Expressive Conversational Speech Synthesis", "pub_year": "2024"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:EUQCXRtRnyEC", "num_citations": 0}, "4FA6C0AAAAAJ:M3NEmzRMIkIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "EditSinger: Zero-Shot Text-Based Singing Voice Editing System with Diverse Prosody Modeling", "pub_year": "2022"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:M3NEmzRMIkIC", "num_citations": 0}, "4FA6C0AAAAAJ:pyW8ca7W8N0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "TETA: Temporal-Enhanced Text-to-Audio Generation"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:pyW8ca7W8N0C", "num_citations": 0}, "4FA6C0AAAAAJ:lSLTfruPkqcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Out-of-distribution Detection with Diffusion-based Neighborhood"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:lSLTfruPkqcC", "num_citations": 0}, "4FA6C0AAAAAJ:O3NaXMp0MMsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FastDiff 2: Dually Incorporating GANs into Diffusion Models for High-Quality Speech Synthesis"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:O3NaXMp0MMsC", "num_citations": 0}, "4FA6C0AAAAAJ:_Qo2XoVZTnwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SynCLR: A Synthesis Framework for Contrastive Learning of out-of-domain Speech Representations"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:_Qo2XoVZTnwC", "num_citations": 0}, "4FA6C0AAAAAJ:Tyk-4Ss8FVUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SimulS2S: End-to-End Simultaneous Speech to Speech Translation"}, "filled": false, "author_pub_id": "4FA6C0AAAAAJ:Tyk-4Ss8FVUC", "num_citations": 0}}, "citedby5y": 6009, "hindex": 30, "hindex5y": 30, "i10index": 47, "i10index5y": 47, "cites_per_year": {"2019": 43, "2020": 219, "2021": 660, "2022": 1054, "2023": 2098, "2024": 1899}, "updated": "2024-09-18 08:04:28.785275"}